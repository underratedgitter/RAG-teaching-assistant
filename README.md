# RAG Teaching Assistant

> **Ask questions about your videos, get AI-powered answers with timestamps**

A powerful AI-driven system that lets you upload lecture videos, automatically transcribes them, and answers your questions with precise timestamps and references.

---

## Table of Contents

- [Quick Start](#quick-start)
- [How It Works](#how-it-works)
- [Pipeline Architecture](#pipeline-architecture)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [Performance](#performance)
- [Troubleshooting](#troubleshooting)
- [Project Structure](#project-structure)
- [Technology Stack](#technology-stack)

---

## Quick Start

### Prerequisites

- Windows/Linux/macOS
- Python 3.10+
- FFmpeg installed
- Ollama running (`ollama serve`)

### 1. Clone and Install

```bash
cd "your/project/path"
pip install -r requirements.txt
```

### 2. Install PyTorch (GPU acceleration)

```bash
# NVIDIA GPU (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# AMD GPU (ROCm)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7

# CPU only
pip install torch torchvision torchaudio
```

### 3. Start Ollama Server

In a separate terminal:

```bash
ollama serve
```

Then pull the models:

```bash
ollama pull nomic-embed-text
ollama pull qwen2.5:1.5b
```

### 4. Run Dashboard

```bash
python dashboard.py
```

The GUI will open. Upload videos and click **"Process Videos"**.

---

## How It Works

The system follows a **Retrieval-Augmented Generation (RAG)** pipeline:

### User Workflow

```
1. Upload Videos
       ‚Üì
2. Click "Process Videos"
       ‚Üì
3. Automatic Processing
   ‚îú‚îÄ Extract audio
   ‚îú‚îÄ Transcribe speech
   ‚îî‚îÄ Create embeddings
       ‚Üì
4. Ask Questions
       ‚Üì
5. Get Answers
   ‚îú‚îÄ Find relevant segments
   ‚îî‚îÄ Generate response with timestamps
```

### What Happens Behind the Scenes

1. **Video Upload** - Place MP4/AVI/MKV/MOV files in the `videos/` folder
2. **Audio Extraction** - Convert video to MP3 using FFmpeg
3. **Transcription** - Use OpenAI Whisper to transcribe audio to text
4. **Chunking** - Split transcription into manageable chunks (by speaker segments)
5. **Embedding** - Generate numeric embeddings for semantic search
6. **Indexing** - Save embeddings for fast retrieval
7. **Query** - When you ask a question, it:
   - Embeds your question
   - Searches for similar chunks using cosine similarity
   - Passes top matches to LLM
   - Returns AI-generated answer with video references

---

## Pipeline Architecture

### Data Flow

```
[VIDEO FILES]
     ‚îÇ
     ‚îú‚îÄ‚Üí video_to_mp3.py (Parallel FFmpeg)
     ‚îÇ       ‚îî‚îÄ‚Üí [MP3 AUDIO FILES]
     ‚îÇ
     ‚îú‚îÄ‚Üí mp3_to_json.py (Whisper base model)
     ‚îÇ       ‚îî‚îÄ‚Üí [JSON TRANSCRIPTS]
     ‚îÇ
     ‚îú‚îÄ‚Üí preprocess_json.py (Ollama embeddings)
     ‚îÇ       ‚îî‚îÄ‚Üí [EMBEDDINGS DATABASE]
     ‚îÇ
[EMBEDDINGS INDEXED]
     ‚îÇ
     ‚îî‚îÄ‚Üí dashboard.py ‚Üí User asks question ‚Üí Get answer with timestamps
```

---

## Requirements

### Software

| Tool | Version | Purpose |
|------|---------|---------|
| **Python** | 3.10+ | Runtime |
| **FFmpeg** | Latest | Video/audio processing |
| **Ollama** | Latest | LLM inference |
| **CUDA** | 11.8+ | GPU acceleration |

### Hardware

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| **CPU** | 4 cores | 8+ cores |
| **RAM** | 8 GB | 16+ GB |
| **GPU** | None | NVIDIA RTX 3050+ |
| **VRAM** | N/A | 4+ GB |

### Ollama Models

```bash
ollama pull nomic-embed-text
ollama pull qwen2.5:1.5b
```

---

## Installation

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Install PyTorch (GPU)

```bash
# NVIDIA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# AMD
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.7

# CPU
pip install torch torchvision torchaudio
```

### 3. Install FFmpeg

**Windows:** https://ffmpeg.org/download.html
**Linux:** `sudo apt-get install ffmpeg`
**Mac:** `brew install ffmpeg`

### 4. Start Ollama

```bash
ollama serve
```

---

## Usage

### Step 1: Upload Videos

Place videos in the `videos/` folder (MP4, AVI, MKV, MOV)

### Step 2: Start Dashboard

```bash
python dashboard.py
```

### Step 3: Click "Process Videos"

Automated pipeline:
- Converts videos to MP3 (parallel)
- Transcribes with Whisper (GPU)
- Generates embeddings
- Indexes for search

### Step 4: Ask Questions

Type natural language questions, get answers with timestamps.

---

## Configuration

### Whisper Model

Edit `mp3_to_json.py`:

```python
model = whisper.load_model("base", device=device)
```

| Model | Speed | Quality | VRAM |
|-------|-------|---------|------|
| **tiny** | ‚ö°‚ö°‚ö°‚ö° | Poor | 1GB |
| **base** | ‚ö°‚ö°‚ö° | Good | 1GB |
| **small** | ‚ö°‚ö° | Very Good | 2GB |
| **medium** | ‚ö° | Excellent | 5GB |
| **large** | üê¢ | Perfect | 10GB |

### LLM Model

Edit `dashboard.py`:

```python
"model": "qwen2.5:1.5b"
```

### Language

Edit `mp3_to_json.py`:

```python
language="en"  # 'hi', 'es', 'fr', etc.
```

---

## Performance

| Operation | CPU | GPU (RTX 3070) |
|-----------|-----|----------------|
| Video ‚Üí MP3 (1 min) | 8s | 8s |
| Transcribe (5 min) | 5 min | 15 sec |
| Embeddings (100 chunks) | 3s | 3s |
| Query | 2s | 1s |
| **Total (5 min video)** | ~5 min | **~20 sec** |

---

## Troubleshooting

### Connection Issues

**"Cannot connect to Ollama"**
```bash
ollama serve
```

**"Model not found"**
```bash
ollama pull nomic-embed-text
ollama pull qwen2.5:1.5b
```

### Processing Issues

**"FFmpeg not found"** - Install from https://ffmpeg.org/download.html

**"Out of memory"** - Use smaller Whisper model (`tiny` or `base`)

**"CUDA out of memory"** - Close other apps or use CPU

---

## Project Structure

```
rag-teach/
‚îú‚îÄ‚îÄ dashboard.py          # GUI application
‚îú‚îÄ‚îÄ video_to_mp3.py       # Video conversion
‚îú‚îÄ‚îÄ mp3_to_json.py        # Transcription
‚îú‚îÄ‚îÄ preprocess_json.py    # Embeddings
‚îú‚îÄ‚îÄ requirements.txt      # Dependencies
‚îú‚îÄ‚îÄ README.md             # Documentation
‚îú‚îÄ‚îÄ videos/               # Input videos
‚îú‚îÄ‚îÄ audios/               # Extracted audio
‚îú‚îÄ‚îÄ jsons/                # Transcripts
‚îú‚îÄ‚îÄ embeddings.joblib     # Indexed data
‚îî‚îÄ‚îÄ embedding_matrix.npy  # Search matrix
```

---

## Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **UI** | Tkinter | GUI |
| **Video** | FFmpeg | Conversion |
| **Audio** | Whisper | Transcription |
| **Embeddings** | Nomic | Vectors |
| **Search** | Scikit-learn | Similarity |
| **LLM** | Qwen 2.5 | Answers |
| **GPU** | PyTorch CUDA | Acceleration |

---

## License

MIT License - Free to use and modify

---

**Built with ‚ù§Ô∏è using Whisper ‚Ä¢ Ollama ‚Ä¢ PyTorch**
